{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch01_04_DNN기초_이진분류모델.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeHuiJong/-Deep_learning/blob/main/ch01_04_DNN%EA%B8%B0%EC%B4%88_%EC%9D%B4%EC%A7%84%EB%B6%84%EB%A5%98%EB%AA%A8%EB%8D%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ch01.04 DNN기초 - 이진분류 모델\n",
        "\n",
        "\n",
        "---\n",
        "* 날짜:\n",
        "* 이름:\n",
        "\n",
        "## 학습내용\n",
        "    - 딥러닝을 이용한 이진분류 모델 구현\n",
        "    - 적절한 손실함수와 최적화 함수 정의\n",
        "    - 평가 및 예측\n",
        "\n",
        "## 학습자료\n",
        "\n",
        "* 모두의딥러닝 11장, 13장\n",
        "* 데이터\n",
        "  * `sornar.csv`\n",
        "  * `pima-indians-diabetes.csv`\n",
        "\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "seed=1\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "```\n",
        "\n",
        "```\n",
        "https://github.com/yebiny/SkillTreePython-DeepLearning.git\n",
        "```"
      ],
      "metadata": {
        "id": "sWs2kEC1_b-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "seed=1\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "3dvXKSSnDQ9V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LeeHuiJong/-Deep_learning"
      ],
      "metadata": {
        "id": "VIgPnWNbUt_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "696ce40b-e37a-40cd-efc0-cc185e04117f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '-Deep_learning'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 154 (delta 16), reused 1 (delta 1), pack-reused 105\u001b[K\n",
            "Receiving objects: 100% (154/154), 81.25 MiB | 14.08 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 소나 데이터 광물 예측\n",
        "---\n",
        "\n",
        "> 1988년 존스홉킨스 대학교의 세즈노프스키(Sejnowski) 교수는 광석과 일반 돌을 가져다 놓고 음파 탐지기를 쏜 후 그 결과를 데이터를 정리했습니다. 신경망이 광석과 돌을 얼마나 잘 구분하는지 알아보도록 합시다.\n",
        "\n",
        "```\n",
        "- 0~59 : 음파 탐지기를 이용해 얻은 값\n",
        "- 60: 광석 구분 {R, M}\n",
        "```\n",
        "<p align='center'>\n",
        "<img src=https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/imgs/ch0104-01.PNG?raw=true width=450>\n",
        "</p>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KOmt3w8_rVe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 데이터 준비"
      ],
      "metadata": {
        "id": "TmgkVAdIfngb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **데이터 로드**\n",
        "* `sonar.csv`"
      ],
      "metadata": {
        "id": "cHXodXKif2BB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2sh64rMrANLD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "ed59a59e-51a6-4791-dd60-2fa8fe738934"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0       1       2       3       4       5       6       7       8   \\\n",
              "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
              "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
              "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
              "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
              "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
              "\n",
              "       9   ...      51      52      53      54      55      56      57  \\\n",
              "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
              "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
              "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
              "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
              "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
              "\n",
              "       58      59  60  \n",
              "0  0.0090  0.0032   R  \n",
              "1  0.0052  0.0044   R  \n",
              "2  0.0095  0.0078   R  \n",
              "3  0.0040  0.0117   R  \n",
              "4  0.0107  0.0094   R  \n",
              "\n",
              "[5 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f5d86f8-8587-413d-ac1d-eaccdb51e0ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 61 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f5d86f8-8587-413d-ac1d-eaccdb51e0ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f5d86f8-8587-413d-ac1d-eaccdb51e0ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f5d86f8-8587-413d-ac1d-eaccdb51e0ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "data_path = '/content/-Deep_learning/dataset/sonar.csv'\n",
        "df = pd.read_csv(data_path, header = None)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **데이터 전처리**"
      ],
      "metadata": {
        "id": "0NL7LyHXrhoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def path2data_sonar(path, seed = 1):\n",
        "  # 데이터 적절히 불러오기\n",
        "  df = pd.read_csv(data_path,\n",
        "                   header = None, # 첫번째 행이 데이터 (컬럼 없음)\n",
        "                   )\n",
        "  \n",
        "  \n",
        "  # x,y 분할\n",
        "  x = df.values[:, :-1] # 모든행(샘플), 0부터 마지막 전까지 열(속성)\n",
        "  y = df.values[:, -1] # 모든행(샘플), 마지막 번째 열(속성)\n",
        "  \n",
        "  # 정규화 전처리(x의 모든속성, y는 하지 않음)\n",
        "  scaler = StandardScaler()\n",
        "  x = scaler.fit_transform(x)\n",
        "  \n",
        "  # y 라벨링(x는 하지 않는다.)\n",
        "  labeling = LabelEncoder()\n",
        "  y = labeling.fit_transform(y)\n",
        "\n",
        "  # train-test 데이터 분할\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, \n",
        "                                                      random_state = seed, \n",
        "                                                      stratify = y) # train, test 분할시 클래스 비율 비슷하게 유지\n",
        "  \n",
        "  return x_train, x_test, y_train, y_test\n",
        "\n",
        "data_path = '/content/-Deep_learning/dataset/sonar.csv'\n",
        "x_train, x_test, y_train, y_test = path2data_sonar(data_path)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "print(x_train[1], y_train[1])"
      ],
      "metadata": {
        "id": "CoWLi5NgraBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79390d98-6820-4412-d6b5-fa2c94f5653b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(145, 60) (63, 60) (145,) (63,)\n",
            "[-0.73091423  0.14791278  0.43217734 -0.193733   -0.27973353 -1.17141213\n",
            " -1.11368502 -1.1830759  -0.61643936  0.02789771 -0.54396541 -0.43025161\n",
            "  0.20832115 -0.57696915 -1.27359777 -0.60100177 -0.1911599  -0.2737382\n",
            "  0.34226731  0.25514539 -0.11259861 -0.65372658 -0.80968198 -1.27254722\n",
            " -0.12615184  0.8203173   0.79833763 -0.82844031 -1.28832161 -1.57084217\n",
            " -1.63565539 -0.34053744  0.08145143 -0.41196074 -0.34881305  0.09887612\n",
            "  0.77837874  0.34473565  1.128427    1.06935769  0.14029395  0.01132786\n",
            " -0.08251782  0.11825963 -0.54032991 -0.66033662 -0.69576299 -0.9575622\n",
            " -0.19317929 -0.27318109 -0.69023617 -0.53275402 -0.71118685  0.88684983\n",
            "  1.34495706 -0.49309408  0.62024838  1.80515572  1.09602656 -0.0612105 ] 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 예측값 분포 확인"
      ],
      "metadata": {
        "id": "J49Ys-SNBKyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(121);sns.countplot(x=y_train);plt.title('train')\n",
        "plt.subplot(122);sns.countplot(x=y_test);plt.title('test')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3vlsRwuoBMcY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "6b0be6f7-06ec-46f0-f405-ca00c0ef8245"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 모델\n",
        "\n",
        "\n",
        "<p align='center'>\n",
        "<img src=https://github.com/yebiny/SkillTreePython-DeepLearning/blob/main/imgs/ch0104-02.PNG?raw=true width=500>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "DHshtWB9r0be"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **모델 생성**"
      ],
      "metadata": {
        "id": "J94jFpWyr2k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers, utils\n",
        "\n",
        "def build_model():\n",
        "  x = layers.Input(shape = (60,)) # 데이터가 주어지면 인풋의 shape는 고정\n",
        "  z = layers.Dense(30, activation = 'relu')(x)\n",
        "  y = layers.Dense(1, activation = 'sigmoid')(z) # 데이터가 주어지면 아웃풋의 shape는 고정(회귀문제는 마지막 아웃풋 shape가 1, 마지막 활성화 함수가 sigmoid)\n",
        "  model = models.Model(x, y, name='sonar_classifier')\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "5BZG1z90rsGc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **모델 시각화**\n",
        "\n",
        "* `model.summary()`\n",
        "* `utils.plot_model()`"
      ],
      "metadata": {
        "id": "1yqXLbEyx5QK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "model.summary()\n",
        "utils.plot_model(model, show_shapes = True)"
      ],
      "metadata": {
        "id": "dKCT38Fsr6dF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "outputId": "7fd37eda-566b-4c19-8e34-29edc8d57f9e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sonar_classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 60)]              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 30)                1830      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 31        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,861\n",
            "Trainable params: 1,861\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 학습"
      ],
      "metadata": {
        "id": "gLuvsUFmwzPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **모델 컴파일**\n",
        "\n",
        "```\n",
        "model.compile(loss, optimizer, metrics) \n",
        "```\n",
        "* `loss` : 'binary_crossentropy'\n",
        "* `optimizer` : 'adam'\n",
        "* `metrics`: 'accuracy'\n"
      ],
      "metadata": {
        "id": "fwQboNHp3EHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "SASPIskxgfRY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **학습**\n",
        "\n",
        "```\n",
        "model.fit(x_train, y_train, epochs, batch_size)\n",
        "```\n",
        "* `x_train` : 넘파이 혹은 텐서 형식의 인풋 데이터\n",
        "* `y_train` : 넘파이 혹은 텐서 형식의 아웃풋 데이터\n",
        "* `epochs` : 학습 횟수\n",
        "* `batch_size` : 배치 사이즈 (업데이트 한번에 사용될 샘플 개수)"
      ],
      "metadata": {
        "id": "JukUpWB4gfRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs = 100, batch_size = 16)"
      ],
      "metadata": {
        "id": "9bgbpUhogfRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7d1323-f99c-47f8-e61d-86f3d3db9df7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 1s 3ms/step - loss: 0.7025 - accuracy: 0.5724\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6059 - accuracy: 0.6690\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7448\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7931\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.8000\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8207\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8276\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8345\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8552\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8483\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8621\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8897\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8897\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8897\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.8966\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.9034\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.9172\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2965 - accuracy: 0.9103\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.9034\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.9034\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2702 - accuracy: 0.9103\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2606 - accuracy: 0.9241\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.9241\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2424 - accuracy: 0.9241\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.9241\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2278 - accuracy: 0.9241\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2217 - accuracy: 0.9310\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2145 - accuracy: 0.9379\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9448\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.9517\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9517\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.9517\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9517\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1783 - accuracy: 0.9586\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1727 - accuracy: 0.9655\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1683 - accuracy: 0.9655\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9655\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.9655\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1555 - accuracy: 0.9724\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9724\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9724\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.9724\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1372 - accuracy: 0.9724\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1333 - accuracy: 0.9793\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1294 - accuracy: 0.9793\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 0.9793\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1227 - accuracy: 0.9793\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9793\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 0.9793\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9862\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1090 - accuracy: 0.9862\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9862\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9931\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.9931\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0971 - accuracy: 0.9931\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9931\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0915 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0888 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 0.9931\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9931\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0734 - accuracy: 0.9931\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9931\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0684 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0385 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0320 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed9cc84910>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 검증 및 예측\n"
      ],
      "metadata": {
        "id": "DyFOnqyNw5_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **검증**\n",
        "\n",
        "```\n",
        "model.evaluate(x_test, y_test)\n",
        "```\n",
        "* `x_test` : 넘파이 혹은 텐서 형식의 인풋 테스트 데이터\n",
        "* `y_test` : 넘파이 혹은 텐서 형식의 아웃풋 테스트 데이터"
      ],
      "metadata": {
        "id": "qlalKZ-a04c3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "uHGyMlf60zng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5017a9-2ae9-4875-a951-2401d0091843"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6305 - accuracy: 0.8413\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6304829120635986, 0.841269850730896]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **예측**\n",
        "\n",
        "```\n",
        "model.predict(x_test)\n",
        "```\n",
        "* `x_test` : 넘파이 혹은 텐서 형식의 인풋 테스트 데이터\n",
        "* `y_test` : 넘파이 혹은 텐서 형식의 아웃풋 테스트 데이터"
      ],
      "metadata": {
        "id": "BITPUIOj07Uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test).flatten()\n",
        "print(y_pred[0], y_test[0])\n",
        "y_pred.shape, y_test.shape"
      ],
      "metadata": {
        "id": "KfDHL4PRv8YD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b6c409-9035-489c-e464-28ebfadd8dc4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08204478 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((63,), (63,))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.round(y_pred)# 반올림 (0.5 기준으로)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRi3rXMAI4QR",
        "outputId": "66de407a-1980-4745-d329-cffb64be4cb1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
              "       1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
              "       1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 예측 시각화"
      ],
      "metadata": {
        "id": "gThN4RCR0_HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# 함수 인풋 배열은 정수가 되야 한다.\n",
        "cm = confusion_matrix(y_test, np.round(y_pred))\n",
        "print(cm)\n",
        "ConfusionMatrixDisplay(cm).plot(cmap='Blues')"
      ],
      "metadata": {
        "id": "TG533VyLwDaK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "0b99712c-d344-432e-b96b-4f6254172806"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[28  6]\n",
            " [ 4 25]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fed9cb43450>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 과제\n",
        "---"
      ],
      "metadata": {
        "id": "ZFrRTgcyipYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 과제1. 이진분류 문제 정리\n",
        "\n",
        "* 예측값의 범위 : 0 에서 1 사이의 확률 값\n",
        "* 예측값의 shape : (샘플개수, ) 혹은 (샘플개수, 1)\n",
        "* 아웃풋 레이어의 노드 개수 : 1\n",
        "* 아웃풋 레이어의 activation : sigmoid\n",
        "* 손실함수 (loss) : binary_crossentropy\n",
        "* 평가함수 (metrics) : accuracy"
      ],
      "metadata": {
        "id": "xjnJSLgXK_Pp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 과제2. 한 셀에 코드 정리하기\n",
        "\n",
        "* 추가 연습\n",
        "  * 모델의 깊이(depth)를 늘려가며 학습해 보세요.\n",
        "  * 모델의 너비(width)를 늘려가며 학습해 보세요."
      ],
      "metadata": {
        "id": "ZvFAB78P1B_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models, layers, utils\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def path2data_sonar(path, seed = 1):\n",
        "  # 데이터 적절히 불러오기\n",
        "  df = pd.read_csv(data_path,\n",
        "                   header = None, # 첫번째 행이 데이터 (컬럼 없음)\n",
        "                   )\n",
        "  \n",
        "  \n",
        "  # x,y 분할\n",
        "  x = df.values[:, :-1] # 모든행(샘플), 0부터 마지막 전까지 열(속성)\n",
        "  y = df.values[:, -1] # 모든행(샘플), 마지막 번째 열(속성)\n",
        "  \n",
        "  # 정규화 전처리(x의 모든속성, y는 하지 않음)\n",
        "  scaler = StandardScaler()\n",
        "  x = scaler.fit_transform(x)\n",
        "  \n",
        "  # y 라벨링(x는 하지 않는다.)\n",
        "  labeling = LabelEncoder()\n",
        "  y = labeling.fit_transform(y)\n",
        "\n",
        "  # train-test 데이터 분할\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, \n",
        "                                                      random_state = seed, \n",
        "                                                      stratify = y) # train, test 분할시 클래스 비율 비슷하게 유지\n",
        "  \n",
        "  return x_train, x_test, y_train, y_test\n",
        "\n",
        "data_path = '/content/-Deep_learning/dataset/sonar.csv'\n",
        "x_train, x_test, y_train, y_test = path2data_sonar(data_path)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "print(x_train[1], y_train[1])\n",
        "\n",
        "\n",
        "# 모델 생성\n",
        "def build_model():\n",
        "  x = layers.Input(shape = (60,)) # 데이터가 주어지면 인풋의 shape는 고정\n",
        "  z = layers.Dense(30, activation = 'relu')(x)\n",
        "  y = layers.Dense(1, activation = 'sigmoid')(z) # 데이터가 주어지면 아웃풋의 shape는 고정(회귀문제는 마지막 아웃풋 shape가 1, 마지막 활성화 함수가 sigmoid)\n",
        "  model = models.Model(x, y, name='sonar_classifier')\n",
        "\n",
        "  return model\n",
        "\n",
        "# 학습\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])\n",
        "model.fit(x_train, y_train, epochs = 100, batch_size = 16)\n",
        "\n",
        "# 예측\n",
        "y_pred = model.predict(x_test).flatten()\n",
        "cm = confusion_matrix(y_test, np.round(y_pred)) # 함수 인풋 배열은 정수가 되야 한다.\n",
        "print(cm)\n",
        "ConfusionMatrixDisplay(cm).plot(cmap='Blues')"
      ],
      "metadata": {
        "id": "v5WYSd9a1Cz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 과제 3. 피마 인디언 당뇨병 예측\n",
        "\n",
        "\n",
        "* `pima-indians-diabetes.csv`\n",
        "```\n",
        "df = pd.read_csv(data_path,\n",
        "                names = [\"pregnant\", \"plasma\", \"pressure\", \"thickness\", \"insulin\", \"BMI\", \"pedigree\", \"age\", \"class\"])\n",
        "```"
      ],
      "metadata": {
        "id": "2K0mAdPzjOAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/-Deep_learning/dataset/pima-indians-diabetes.csv',\n",
        "              names = [\"pregnant\", \"plasma\", \"pressure\", \"thickness\", \"insulin\", \"BMI\", \"pedigree\", \"age\", \"class\"])\n",
        "df"
      ],
      "metadata": {
        "id": "Ppi8p2S_HsVb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "4c966e57-2b0d-468a-aff4-156f1dd694d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     pregnant  plasma  pressure  thickness  insulin   BMI  pedigree  age  \\\n",
              "0           6     148        72         35        0  33.6     0.627   50   \n",
              "1           1      85        66         29        0  26.6     0.351   31   \n",
              "2           8     183        64          0        0  23.3     0.672   32   \n",
              "3           1      89        66         23       94  28.1     0.167   21   \n",
              "4           0     137        40         35      168  43.1     2.288   33   \n",
              "..        ...     ...       ...        ...      ...   ...       ...  ...   \n",
              "763        10     101        76         48      180  32.9     0.171   63   \n",
              "764         2     122        70         27        0  36.8     0.340   27   \n",
              "765         5     121        72         23      112  26.2     0.245   30   \n",
              "766         1     126        60          0        0  30.1     0.349   47   \n",
              "767         1      93        70         31        0  30.4     0.315   23   \n",
              "\n",
              "     class  \n",
              "0        1  \n",
              "1        0  \n",
              "2        1  \n",
              "3        0  \n",
              "4        1  \n",
              "..     ...  \n",
              "763      0  \n",
              "764      0  \n",
              "765      0  \n",
              "766      1  \n",
              "767      0  \n",
              "\n",
              "[768 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4cf468eb-04b9-4d8a-a111-a09c6d8726be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pregnant</th>\n",
              "      <th>plasma</th>\n",
              "      <th>pressure</th>\n",
              "      <th>thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>pedigree</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cf468eb-04b9-4d8a-a111-a09c6d8726be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4cf468eb-04b9-4d8a-a111-a09c6d8726be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4cf468eb-04b9-4d8a-a111-a09c6d8726be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models, layers, utils\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def path2data_sonar(path, seed = 1):\n",
        "  # 데이터 적절히 불러오기\n",
        "  df = pd.read_csv('/content/-Deep_learning/dataset/pima-indians-diabetes.csv',\n",
        "                   names = [\"pregnant\", \"plasma\", \"pressure\", \"thickness\", \"insulin\", \"BMI\", \"pedigree\", \"age\", \"class\"])\n",
        "  \n",
        "  \n",
        "  # x,y 분할\n",
        "  x = df.values[:, :-1] # 모든행(샘플), 0부터 마지막 전까지 열(속성)\n",
        "  y = df.values[:, -1] # 모든행(샘플), 마지막 번째 열(속성)\n",
        "  \n",
        "  # 정규화 전처리(x의 모든속성, y는 하지 않음)\n",
        "  scaler = StandardScaler()\n",
        "  x = scaler.fit_transform(x)\n",
        "\n",
        "  # train-test 데이터 분할\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, \n",
        "                                                      random_state = seed, \n",
        "                                                      stratify = y) # train, test 분할시 클래스 비율 비슷하게 유지\n",
        "  \n",
        "  return x_train, x_test, y_train, y_test\n",
        "\n",
        "data_path = '/content/-Deep_learning/dataset/pima-indians-diabetes.csv'\n",
        "x_train, x_test, y_train, y_test = path2data_sonar(data_path)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "print(x_train[1], y_train[1])\n",
        "\n",
        "\n",
        "# 모델 생성\n",
        "def build_model():\n",
        "  x = layers.Input(shape = (8),) # 데이터가 주어지면 인풋의 shape는 고정\n",
        "  z = layers.Dense(20, activation = 'relu')(x)\n",
        "  z = layers.Dense(20, activation = 'relu')(x)\n",
        "  y = layers.Dense(1, activation = 'sigmoid')(z) # 데이터가 주어지면 아웃풋의 shape는 고정(회귀문제는 마지막 아웃풋 shape가 1, 마지막 활성화 함수가 sigmoid)\n",
        "  model = models.Model(x, y, name='pima_classifier')\n",
        "\n",
        "  return model\n",
        "\n",
        "# 학습\n",
        "model = build_model()\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])\n",
        "model.fit(x_train, y_train, epochs = 200, batch_size = 16)\n",
        "\n",
        "# 예측 및 결과 시각화\n",
        "y_pred = model.predict(x_test).flatten()\n",
        "cm = confusion_matrix(y_test, np.round(y_pred)) # 함수 인풋 배열은 정수가 되야 한다.\n",
        "ConfusionMatrixDisplay(cm).plot(cmap='Blues')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cXdYmGGFQ-5A",
        "outputId": "5fee83a7-1646-4959-8c98-b236c726cb2d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(537, 8) (231, 8) (537,) (231,)\n",
            "[-0.84488505 -0.74783062  0.04624525  1.22091023 -0.69289057  0.77514938\n",
            " -0.76673656 -0.27575966] 0.0\n",
            "Epoch 1/200\n",
            "34/34 [==============================] - 1s 2ms/step - loss: 0.6590 - accuracy: 0.6443\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.6611\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.6853\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7058\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7430\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7467\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7616\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7672\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7672\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7858\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7914\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7896\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7933\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7970\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8007\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8026\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7989\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8045\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8063\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.8063\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8026\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8045\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8045\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8026\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8007\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8045\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8026\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8045\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8026\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8045\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8063\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8026\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7989\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8045\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8082\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8063\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8045\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8007\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8007\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8045\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8007\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8026\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8026\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8026\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8045\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8045\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8045\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8045\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8045\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8063\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8026\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8082\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8045\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8063\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8082\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8063\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8082\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8045\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8063\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8101\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8082\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8101\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8101\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8082\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8082\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8101\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8119\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8119\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8119\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8119\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3996 - accuracy: 0.8119\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8119\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8119\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8119\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8119\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8101\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8119\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8138\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8138\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8156\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8212\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8138\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8119\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8175\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8231\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8175\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8156\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8138\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8156\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8138\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8194\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8138\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8138\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8156\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8194\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8194\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8194\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8231\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8212\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8212\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8212\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8250\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8231\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8231\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8250\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8250\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8231\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8268\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8231\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8268\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8268\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8287\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8268\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8305\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8268\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8287\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8305\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8287\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8305\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8287\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8287\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8287\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8287\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8287\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8324\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8305\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8324\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8324\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8250\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8287\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8287\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8361\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8324\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8268\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8324\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8324\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3728 - accuracy: 0.8268\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8305\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8287\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8324\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8305\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8287\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8287\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8324\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8324\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8324\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8305\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8324\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8324\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8305\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8305\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8324\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8324\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8305\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8305\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8305\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8324\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8324\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8324\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8287\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8343\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8287\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.8305\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8287\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.8268\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8324\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3626 - accuracy: 0.8343\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8305\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8361\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8343\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8287\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8268\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8361\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8324\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8361\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8343\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8380\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.8343\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8305\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8380\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8361\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8380\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8343\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8343\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8380\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8305\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.8380\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8343\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8361\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3575 - accuracy: 0.8343\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8380\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3566 - accuracy: 0.8343\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8361\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8380\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8380\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3569 - accuracy: 0.8343\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8343\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8343\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3553 - accuracy: 0.8380\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8380\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f977cb5e8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### | 과제 4. 생각해보기\n",
        "\n",
        "데이터가 불균형 할 때 딥러닝에서는 어떠한 방법을 써서 이를 해결 하나요? \n"
      ],
      "metadata": {
        "id": "s4VjzrycjTUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# under sampling 이나 over sampling 을 통해 균형을 맞춰준다\n",
        "# x,y 라는 데이터 셋이 존재할때 y의 데이터 양이 너무 적거나 많을 경우 그 비율에 맞춰서 x의 데이터 양을 조절해주는 기법을 말한다."
      ],
      "metadata": {
        "id": "tcMHkA5BjSho"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}